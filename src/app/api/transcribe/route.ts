import { NextRequest, NextResponse } from 'next/server'
import OpenAI from 'openai'

// Initialize OpenAI client
const getOpenAIClient = (apiKey: string) => {
  return new OpenAI({
    apiKey: apiKey,
  })
}

// POST endpoint for STT (Speech-to-Text)
export async function POST(request: NextRequest) {
  try {
    const formData = await request.formData()
    const audioFile = formData.get('audio') as File
    const apiKey = formData.get('apiKey') as string
    const language = formData.get('language') as string || 'fr'
    
    if (!apiKey) {
      return NextResponse.json(
        { error: 'Cl√© API OpenAI manquante' },
        { status: 400 }
      )
    }
    
    if (!audioFile) {
      return NextResponse.json(
        { error: 'Fichier audio manquant' },
        { status: 400 }
      )
    }

    const openai = getOpenAIClient(apiKey)
    
    console.log('üéôÔ∏è STT API: Processing audio file:', audioFile.name, 'Size:', audioFile.size)
    
    // Convert File to format compatible with OpenAI
    const audioBuffer = await audioFile.arrayBuffer()
    const audioBlob = new Blob([audioBuffer], { type: audioFile.type })
    
    // Create a File object with proper name and extension
    const audioFileForAPI = new File([audioBlob], 'audio.webm', { 
      type: audioFile.type 
    })
    
    const transcription = await openai.audio.transcriptions.create({
      file: audioFileForAPI,
      model: "whisper-1",
      language: language === 'auto' ? undefined : language,
      response_format: "verbose_json", // Plus de d√©tails pour debugging
      temperature: 0.0, // Plus d√©terministe
      prompt: "Transcription en fran√ßais. Ponctuation correcte. √âviter les hallucinations."
    })
    
    console.log('‚úÖ STT API: Transcription completed:', {
      text: transcription.text?.substring(0, 100) + '...',
      duration: transcription.duration,
      language: transcription.language,
      confidence: transcription.segments?.[0]?.avg_logprob
    })
    
    return NextResponse.json({
      transcript: transcription.text || transcription,
      language: transcription.language || language,
      duration: transcription.duration,
      confidence: transcription.segments?.[0]?.avg_logprob,
      success: true
    })
    
  } catch (error: unknown) {
    console.error('‚ùå STT API Error:', error)
    
    let errorMessage = 'Erreur lors de la transcription audio'
    let statusCode = 500
    
    const errorObj = error as { status?: number; message?: string }
    
    if (errorObj.status === 400) {
      errorMessage = 'Fichier audio invalide - V√©rifiez le format et la taille'
      statusCode = 400
    } else if (errorObj.status === 401) {
      errorMessage = 'Cl√© API OpenAI invalide ou expir√©e'
      statusCode = 401
    } else if (errorObj.status === 429) {
      errorMessage = 'Limite de taux OpenAI d√©pass√©e - Veuillez patienter'
      statusCode = 429
    }
    
    return NextResponse.json(
      { error: errorMessage, details: errorObj.message || 'Erreur inconnue', success: false },
      { status: statusCode }
    )
  }
}