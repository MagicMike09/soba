import { NextRequest, NextResponse } from 'next/server'
import OpenAI from 'openai'

// Initialize OpenAI client
const getOpenAIClient = (apiKey: string) => {
  return new OpenAI({
    apiKey: apiKey,
  })
}

// POST endpoint for LLM Chat Completion
export async function POST(request: NextRequest) {
  try {
    const { 
      messages, 
      systemPrompt, 
      model = 'gpt-4', 
      temperature = 0.7, 
      apiKey,
      userContext 
    } = await request.json()
    
    if (!apiKey) {
      return NextResponse.json(
        { error: 'Cl√© API OpenAI manquante' },
        { status: 400 }
      )
    }
    
    if (!messages || !Array.isArray(messages)) {
      return NextResponse.json(
        { error: 'Messages manquants ou format invalide' },
        { status: 400 }
      )
    }

    const openai = getOpenAIClient(apiKey)
    
    console.log('üß† Chat API: Generating response for', messages.length, 'messages')
    
    // Prepare messages for OpenAI
    const formattedMessages = [
      {
        role: 'system' as const,
        content: systemPrompt || 'Tu es un assistant virtuel fran√ßais professionnel et serviable.'
      },
      ...messages.map((msg: { role: 'user' | 'assistant'; content: string }) => ({
        role: msg.role as 'user' | 'assistant',
        content: msg.content
      }))
    ]
    
    // Add user context to system message if provided
    if (userContext) {
      formattedMessages[0].content += `\n\nCONTEXTE UTILISATEUR:\n${JSON.stringify(userContext, null, 2)}`
    }
    
    const completion = await openai.chat.completions.create({
      model: model,
      messages: formattedMessages,
      temperature: temperature,
      max_tokens: 1500,
      stream: false
    })

    const responseContent = completion.choices[0]?.message?.content || 'D√©sol√©, je n\'ai pas pu g√©n√©rer de r√©ponse.'
    
    console.log('‚úÖ Chat API: Response generated:', responseContent.substring(0, 100) + '...')
    
    return NextResponse.json({
      response: responseContent,
      model: model,
      usage: completion.usage,
      success: true
    })
    
  } catch (error: unknown) {
    console.error('‚ùå Chat API Error:', error)
    
    let errorMessage = 'Erreur lors de la g√©n√©ration de r√©ponse'
    let statusCode = 500
    
    const errorObj = error as { status?: number; message?: string }
    
    if (errorObj.status === 400) {
      errorMessage = 'Param√®tres invalides - V√©rifiez les messages et le mod√®le'
      statusCode = 400
    } else if (errorObj.status === 401) {
      errorMessage = 'Cl√© API OpenAI invalide ou expir√©e'
      statusCode = 401
    } else if (errorObj.status === 429) {
      errorMessage = 'Limite de taux OpenAI d√©pass√©e - Veuillez patienter'
      statusCode = 429
    } else if (errorObj.status === 402) {
      errorMessage = 'Quota OpenAI insuffisant - V√©rifiez votre facturation'
      statusCode = 402
    }
    
    return NextResponse.json(
      { error: errorMessage, details: errorObj.message || 'Erreur inconnue', success: false },
      { status: statusCode }
    )
  }
}